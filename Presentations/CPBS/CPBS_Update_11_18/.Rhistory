library(plyr)
library(dplyr)
library(dada2)
library(phyloseq)
library(plyr)
library(dplyr)
library(dada2)
path = "/Users/stronglab2/Documents/Strong_Lab/Microbiome/BRASS_Asthma/Test_environment/Reads/"
fnFS = sort(list.files(path, pattern = "_L001_R1_001.fastq"))
fnRs = sort(list.files(path, pattern = "_L001_R2_001.fastq"))
samp_names = sapply(strsplit(fnFS, "_"), `[`,2)
fnFS = file.path(path, fnFS)
fnRs = file.path(path, fnRs)
filt_path = file.path(path, "filtered")
filtFs = file.path(filt_path, paste0(samp_names, "F_filt.fastq.gz"))
filtRs = file.path(filt_path, paste0(samp_names, "R_filt.fastq.gz"))
out = filterAndTrim(fnFS, filtFs, fnRs, filtRs, truncLen = c(280, 279), maxN = 0, truncQ = 2, rm.phix = TRUE,compress = TRUE,multithread = TRUE)
head(out)
?filterAndTrim
errF = learnErrors(filtFs, multithread = TRUE)
errR = learnErrors(filtRs, multithread = TRUE)
derepFs = derepFastq(filtFs, verbose = T)
derepRs = derepFastq(filtRs, verbose = T)
names(derepFs) = samp_names
names(derepRs) = samp_names
dadaFs = dada(derepFs, err = errF, multithread = T)
dadaRs = dada(derepRs, err = errR, multithread = T)
mergers = mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = T, returnRejects=TRUE)
seqtab = makeSequenceTable(mergers)
dim(seqtab)
seqtab.nochim = removeBimeraDenovo(seqtab, method = "consensus", multithread=TRUE, verbose = T)
sum(seqtab.nochim)/sum(seqtab)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- samp_names
write.csv(track, file = "Read_distro_thru_Processing.csv")
#save(seqtab, file = "seq_table_11_11_17.RData")
#save(seqtab.nochim, file = "seq_table_chimeras_filtered_11_11_17.RData")
fnFS = sort(list.files(path, pattern = "_L001_R1_001.fastq"))
fnRs = sort(list.files(path, pattern = "_L001_R2_001.fastq"))
samp_names = sapply(strsplit(fnFS, "_"), `[`,2)
fnFS = file.path(path, fnFS)
fnRs = file.path(path, fnRs)
filt_path = file.path(path, "filtered")
filtFs = file.path(filt_path, paste0(samp_names, "F_filt.fastq.gz"))
filtRs = file.path(filt_path, paste0(samp_names, "R_filt.fastq.gz"))
out = filterAndTrim(fnFS, filtFs, fnRs, filtRs, truncLen = c(270, 270), maxN = 0, truncQ = 2, rm.phix = TRUE,compress = TRUE,multithread = TRUE)
head(out)
errF = learnErrors(filtFs, multithread = TRUE)
errR = learnErrors(filtRs, multithread = TRUE)
seqtab.nochim = removeBimeraDenovo(seqtab, method = "pooled", multithread=TRUE, verbose = T)
sum(seqtab.nochim)/sum(seqtab)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- samp_names
write.csv(track, file = "Read_distro_thru_Processing.csv")
seqtab.nochim = removeBimeraDenovo(seqtab, method = "pooled", multithread=TRUE, verbose = T)
sum(seqtab.nochim)/sum(seqtab)
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchim")
rownames(track) <- samp_names
write.csv(track, file = "Read_distro_thru_Processing.csv")
#save(seqtab, file = "seq_table_11_11_17.RData")
#save(seqtab.nochim, file = "seq_table_chimeras_filtered_11_11_17.RData")
derepFs = derepFastq(filtFs, verbose = T)
derepRs = derepFastq(filtRs, verbose = T)
names(derepFs) = samp_names
names(derepRs) = samp_names
dadaFs = dada(derepFs, err = errF, multithread = T)
dadaRs = dada(derepRs, err = errR, multithread = T)
mergers = mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = T, returnRejects=TRUE)
seqtab = makeSequenceTable(mergers)
dim(seqtab)
seqtab.nochim = removeBimeraDenovo(seqtab, method = "pooled", multithread=TRUE, verbose = T)
sum(seqtab.nochim)/sum(seqtab)
seqtab.nochim = removeBimeraDenovo(seqtab, method = "consensus", multithread=TRUE, verbose = T)
sum(seqtab.nochim)/sum(seqtab)
setwd("~/Documents/Strong_Lab/Microbiome/Asthma_Analysis_Sinai_NJH/Asthma_Analysis_Cleaned_up_11_11_17")
library(phyloseq)
library(ggplot2)
library(seqinr)
load("data/Taxa_Silva_Trimmed_Primers_11_6_17_NoEE.RData")
load("data/seq_table_chimeras_filtered_11_11_17.RData")
unique_genus = as.data.frame(unique(taxa_silva[,6]))
rowSums(seqtab.nochim)
blanks = c('CLSB160063', 'CLSB160064', 'ENSB160029', 'ENSB160031')
edited_seqtab.nochim = seqtab.nochim[!rownames(seqtab.nochim) %in% blanks,]
samdf = read.csv(file = "metadata/edited_Matrix_Asthma_9_5_17.txt", sep='\t', header = T, stringsAsFactors = FALSE)
edited_samdf = samdf[!samdf$Sample_Name %in% blanks,]
samples.out = rownames(edited_seqtab.nochim)
rownames(edited_samdf) = samples.out
ps = phyloseq(otu_table(edited_seqtab.nochim,taxa_are_rows = FALSE),sample_data(edited_samdf), tax_table(taxa_silva))
View(samdf)
ps_2 = rarefy_even_depth(ps, sample.size = 2028, rngseed=1, replace = F, trimOTUs = T)
tab = as.data.frame(ps_2@otu_table)
df_2 = as.data.frame(ps_2@sam_data)
View(df_2)
rowSums(seqtab.nochim)
load("seq_table_chimeras_filtered.RData")
setwd("~/Documents/Github_Repos/18S-16S/R_Pipeline")
load("seq_table_chimeras_filtered.RData")
taxa_silva = assignTaxonomy(seqtab.nochim, "/Users/stronglab2/Downloads/Databases/DADA2_Databases/Silva/silva_nr_v132_train_set.fa", multithread = T)
library(dada2, quietly=T)
taxa_silva = assignTaxonomy(seqtab.nochim, "/Users/stronglab2/Downloads/Databases/DADA2_Databases/Silva/silva_nr_v132_train_set.fa", multithread = T)
View(seqtab.nochim)
save(taxa_silva, file = "Taxa_Silva.RData")
View(taxa_silva)
taxa_silva_2 = assignSpecies(seqtab.nochim, "/Users/stronglab2/Downloads/Databases/DADA2_Databases/Silva/other/silva_species_assignment_v132.fa.gz", multithread=T)
taxa_silva_2 = assignSpecies(seqtab.nochim, "/Users/stronglab2/Downloads/Databases/DADA2_Databases/Silva/other/silva_species_assignment_v132.fa.gz")
View(taxa_silva_2)
View(taxa_silva)
x = cbind(taxa_silva, taxa_silva_2)
View(x)
View(taxa_silva_2)
View(seqtab.nochim)
colSums(seqtab.nochim)
rowsum(seqtab.nochim)
rowSums(seqtab.nochim)
View(taxa_silva_2)
setwd("~/Documents/Github_Repos/Tex_Documents/Presentations/CPBS/CPBS_Update_11_18")
